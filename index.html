<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="viewport" content="width=device-width, initial-scale=1">

    <title>ICML 2020 Workshop</title>

    <!-- css -->
<link rel="icon" href="header.jpg" type="image/gif">

    <link rel="stylesheet" href="bower_components/bootstrap/dist/css/bootstrap.min.css">
    <link rel="stylesheet" href="bower_components/ionicons/css/ionicons.min.css">
    <link rel="stylesheet" href="assets/css/main.css">
</head>
<body data-spy="scroll" data-target="#site-nav">
    <nav id="site-nav" class="navbar navbar-fixed-top navbar-custom">
        <div class="container">
            <div class="navbar-header">

                <!-- logo -->
                <div class="site-branding">
                <p>TBD</p>
                </div>

                <button type="button" class="navbar-toggle collapsed" data-toggle="collapse" data-target="#navbar-items" aria-expanded="false">
                    <span class="sr-only">Toggle navigation</span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                    <span class="icon-bar"></span>
                </button>

            </div><!-- /.navbar-header -->

            <div class="collapse navbar-collapse" id="navbar-items">
                <ul class="nav navbar-nav navbar-right">

                    <!-- navigation menu -->
                    <li class="active"><a data-scroll href="#overview">Overview</a></li>
                    <li><a data-scroll href="#speakers">Invited Speakers</a></li>           
                    <li><a data-scroll href="#contribution">Call for Papers</a></li>
                    <li><a data-scroll href="#schedule">Schedule</a></li> 
                    <li><a data-scroll href="#people">People</a></li>                  

                    <!-- <li><a data-scroll href="#">Sponsorship</a></li>
                    <li><a data-scroll href="#peop">Organizers</a></li>
               <li><a data-scroll href="#photos">Photos</a></li>-->
                
                </ul>
            </div>
        </div><!-- /.container -->
    </nav>

    <header id="site-header" class="site-header valign-center"> 
        <div class="intro">

            <!--<h2>25 April, 2015 / Townhall California</h2>-->
            
            <h1>Graph Neural Networks: A Bridge Between Perception and Reasoning?</h1>
            
            <p>ICML 2020 Workshop</p>
            
            <!--<a class="btn btn-white" data-scroll href="#registration">Register Now</a>-->
        
        </div>
    </header>

    <section id="overview" class="section overview">
        <div class="container">
            <div class="row">

                <div class="col-sm-12">
                    <h3 class="section-title">Overview</h3>

                    <p> Deep learning has achieved great success in a variety of tasks such as recognizing objects in images, predicting the sentiment of sentences, or speech synthesis by training on a large-amount of data. However, most of existing success are mainly focusing on perceptual tasks, which is also known as System I intelligence. In real world, many complicated tasks, such as autonomous driving, public policy decision making, and multi-hop question answering, require understanding the relationship between high-level variables in the data to perform logical reasoning, which is known as System II intelligence.  </p>

                    <p>Graph is an important structure for System II intelligence, with the universal representation ability to capture the relationship between different variables, and support interpretability, causality, and transferability / inductive generalization. Traditional logic and symbolic reasoning over graphs has relied on methods and tools which are very different from deep learning models, such Prolog language, SMT solvers, constrained optimization and discrete algorithms. Is such a methodology separation between System I and System II intelligence necessary? Can we build a bridge to smoothly connect these two systems, and create higher order artificial intelligence?  </p>

                    <p>Graph neural networks, have emerged as the tool of choice for graph representation learning, which has led to impressive progress in many classification and regression problems such as chemical synthesis, 3D-vision, recommender systems and social network analysis. However, prediction and classification tasks can be very different from logic reasoning. <b> Can graph neural networks be the key bridge to connect System I and System II intelligence? Is there any other more general alternative?</b> </p>

                    <p>Bits and pieces of evidence can be gleaned from recent literature, suggesting graph neural networks may be a general tool tomake such a connection. For example, (Battaglia et al., 2018) viewed graph neural networks as tools to incorporate explicitlylogic reasoning bias. (Kipf et al., 2018) used graph neural network to reason about interacting systems, (Manhaeve et al.,2018; Zhang et al., 2020) used neural networks for logic and probabilistic inference, (Hudson & Manning, 2019; Hu et al.,2019) used graph neural networks for reasoning on scene graphs for visual question reasoning, (Qu & Tang, 2019) studiedreasoning on knowledge graphs with graph neural networks, and (Khalil et al., 2017; Xu et al., 2018; Velickovic et al., 2019; Sato et al., 2019) used graph neural networks for graph algorithms.  However, there can be still be a long way to go fora satisfactory and definite answers on the ability of graph neural networks for automatically discovering logic rules, andconducting long-range multi-step complex reasoning in combination with perception inputs such as language, vision, spatialand temporal variation. </p>

                    <p>The goal of this workshop is to bring researchers from previously separate fields, such as deep learning, logic/symbolic reasoning, statistical relational learning, and graph algorithms, into a common roof to discuss this potential interface and integration between System I and System intelligence. By providing a venue for the confluence of new advances in theoretical foundations, models and algorithms, as well as empirical discoveries, new benchmarks and impactful applications, we hope this can shed light on graph neural networks as the bridge to higher order intelligence, and spark new ideas along this direction. </p>

                    <p>The Topics discussed in this workshop will include but are not limited to: </p>
                    
                    <ul class="list-arrow-right">
                        <li>Deep learning methods on knowledge graphs and relational data.</li>
                        <li>Deep learning for statistical relational learning (e.g., Markov networks, conditional random fields, Markov logic networks).</li>
                        <li>Deep learning for graph algorithms (e.g., combinatorial and iterative algorithms).</li>
                        <li>Neural-symbolic integration.</li>
                        <li>Deep relational or object-level reasoning in machine perception.</li>
                        <li>Relational/structured inductive biases for deep reinforcement learning.</li>
                        <li>Theoretical foundation of graph neural networks for logic reasoning.</li>
                        <li>Deep learning for inductive logic programming.</li>
                        <li>Applications in different fields such as computer vision, natural language understanding, healthcare and other sciences.</li>
                        <li>Benchmark data sets and open source libraries.</li>
                        <li>Other mechanisms such as attention and consciousness.</li>               
                    </ul>

                </div>
            </div>
        </div>
    </section>

    <section id="speakers" class="section speakers">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Invited Speakers</h3>
                    <p> The invited speakers include prominent researchers from seemingly unrelated fields, such as deep learning, logic reasoning, statistical relation learning, graph algorithms and cognitive science, who are converging to the topic of perception and reasoning integration. These prominent researchers will provide a broad view of the subject from the perspective of language, vision and cognitive science, covering aspects of modeling, algorithms, theory as well as benchmarks. </p>

                    <ul class="list-arrow-right">
                        <li>Yoshua Bengio, University of Montreal & Mila</li>
                        <li>Ruslan Salakhutdinov, CMU</li> 
                        <li>Christopher Manning, Stanford</li> 
                        <li>Trevor Darrel, Berkeley</li> 
                        <li>William W. Cohen, Google AI</li> 
                        <li>Luc De Raedt, KU Leuven</li> 
                        <li>Pablo Barceló, PUC Chile & IMFD Chile</li> 
                        <li>Hisashi Kashima, Kyoto University</li> 
                        <li>Stefanie Jegelka, MIT</li> 
                        <li>Regina Barzilay, MIT</li> 
                        <li>Joshua Tenenbaum, MIT</li> 
                        <li>Jennifer Neville, Purdue University</li> 
                    </ul>
                </div>
            </div>
        </div>
    </section>

    <section id="contribution" class="section overview">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Call for Papers</h3>
                    <p>TBD</p>
                </div>
            </div>
        </div>
    </section>

    <section id="schedule" class="section schedule">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">Tentative Schedule</h3>
                    08:45 AM Opening remarks </br>
                    09:00 AM Invited Talk 1 </br>
                    09:30 AM Contributed Talk (1) </br>
                    09:45 AM Poster spotlights 1 (Spotlight talks) </br>
                    10:00 AM Morning poster session and coffee break (Posters) </br>
                    11:00 AM Invited Talk 2 </br>
                    11:30 AM Invited Talk 3 </br>
                    12:00 PM Contributed Talk (2) </br>
                    12:15 PM Poster spotlights 2 (Spotlight talks) </br>
                    12:30 PM Lunch break (Break) </br>
                    02:00 PM Invited Talk 4 </br>
                    02:30 PM Invited Talk 5 </br>
                    03:00 PM Contributed Talk (3) </br>
                    03:15 PM Poster spotlights 3 (Spotlight talks) </br>
                    03:30 PM Afternoon poster session and coffee break (Posters) </br>
                    04:30 PM Invited Talk 6 </br>
                </div>
            </div>
        </div>
    </section>

    <section id="people" class="section people">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <h3 class="section-title">People</h3>
                    <h4>Organizers</h4>
                    <ul>

                    <li><a href="https://www.cc.gatech.edu/~lsong/">Le Song</a> (<a href="https://scholar.google.de/citations?user=Xl4E0CsAAAAJ">Googel scholar</a>) </li>
                    <p>1. Email:<br> lsong@cc.gatech.edu
                    <br>2. Research expertise:<br> Le is an Associate Professor in the College of Computing, an Associate Director of the Center for Machine Learning, Georgia Institute of Technology. My principal research direction is machine learning, especially nonlinear models, such as kernel methods and deep learning, probabilistic graphical models. Before I joined the Georgia Institute of Technology in 2011, I was a postdoc in the Department of Machine Learning, Carnegie Mellon University, and a research scientist at Google. I am also the recipient of the NSF CAREER Award’14, and many best paper awards, including the NIPS’17 Materials Science Workshop Best Paper Award, the Recsys’16 Deep Learning Workshop Best Paper Award, AISTATS'16 Best Student Paper Award, IPDPS'15 Best Paper Award, NIPS’13 Outstanding Paper Award, and ICML’10 Best Paper Award. I have served as the area chair or senior program committee for many leading machine learning and AI conferences such as ICML, NIPS, AISTATS, AAAI, and IJCAI, and the action editor for JMLR and IEEE TPAMI.
                    <br>3. Previous experience:<br> Le has co-organized workshops at ICML 2015, the Simon Institute 2017, WWW 2015, NIPS 2019, 2014 and 2012. </p>

                    <li><a href="www.jian-tang.com">Jian Tang</a> (<a href="https://scholar.google.com/citations?user=1ir6WUEAAAAJ&hl=en">Googel scholar</a>) </li>
                    <p>1. Email:<br> jian.tang@hec.ca
                    <br>2. Research expertise:<br> Jian is an assistant professor at HEC Montreal and also a core faculty member at Mila-Quebec AI Institute. He is a recipient of the first cohort of Canada AI Research Chairs. His main research interest is graph representation learning and graph neural networks with applications in knowledge graphs, drug discovery, and recommender systems. Before joining HEC Montreal, he was a postdoc at University of Michigan and also Carnegie Mellon University, and also a researcher at Microsoft Research Asia. He received a few best paper awards including ICML'14 Best Paper Award, WWW'16 Best Paper Nomination, and Best Paper Award at KDD'19 Workshop on Deep Learning Practice for High-dimensional Space data. He published one of the earliest work on graph representation learning---the LINE algorithm---which has been cited close to 1,900 times since it was published in 2015.  
                    <br>3. Previous experience:<br> Jian has co-organized workshops at SDM'19, CIKM'19, AAAI'20. </p>

                    </ul>
                </div>
            </div>
        </div>
    </section>

    <footer class="site-footer">
        <div class="container">
            <div class="row">
                <div class="col-md-12">
                    <p class="site-info">Designed and Developed by <a href="http://technextit.com">Technext Limited</a></p>
<!--                    <ul class="social-block">
                        <li><a href=""><i class="ion-social-twitter"></i></a></li>
                        <li><a href=""><i class="ion-social-facebook"></i></a></li>
                        <li><a href=""><i class="ion-social-linkedin-outline"></i></a></li>
                        <li><a href=""><i class="ion-social-googleplus"></i></a></li>
                    </ul>-->
                </div>
            </div>
        </div>
    </footer>

    <!-- script -->
    <script src="bower_components/jquery/dist/jquery.min.js"></script>
    <script src="bower_components/bootstrap/dist/js/bootstrap.min.js"></script>
    <script src="bower_components/smooth-scroll/dist/js/smooth-scroll.min.js"></script>
    <script src="assets/js/main.js"></script>
</body>
</html>
